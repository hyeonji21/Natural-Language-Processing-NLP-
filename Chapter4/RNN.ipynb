{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순환 신경망 모델 분류\n",
    "\n",
    "##### 순서가 있는 데이터, 즉 문장 데이터를 입력해서 문장 흐름에서 패턴을 찾아 분류\n",
    "##### 텍스트 정보를 입력해서 문장에 대한 특징 정보를 추출 (이미 주어진 단어 특징 벡터를 활용해 모델 학습 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 랜덤 시드 고정 : 모델과 샘플링을 하는 모든 랜덤 변수의 상태를 고정하기 위한 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = 'C:/Users/0105l/Desktop/고려대학교/대학교_비교과/2021.1학기/KUS실전연구문제단/자연어처리책 실습/data_in/'\n",
    "DATA_OUT_PATH = 'C:/Users/0105l/Desktop/고려대학교/대학교_비교과/2021.1학기/KUS실전연구문제단/자연어처리책 실습/data_out/'\n",
    "TRAIN_INPUT_DATA = 'train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = np.load(open(DATA_IN_PATH + TRAIN_INPUT_DATA, 'rb'))\n",
    "train_input = pad_sequences(train_input, maxlen=train_input.shape[1])\n",
    "train_label = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnn_classifier_en'\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 5\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = train_input.shape[1]\n",
    "\n",
    "kargs = {'model_name':model_name,\n",
    "        'vocab_size':prepro_configs['vocab_size'],\n",
    "        'embedding_dimension': 100,\n",
    "        'dropout_rate': 0.2,\n",
    "        'lstm_dimension': 150,\n",
    "        'dense_dimension': 150,\n",
    "        'output_dimension':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(RNNClassifier, self).__init__(name=kargs['model_name'])\n",
    "        self.embedding = layers.Embedding(input_dim=kargs['vocab_size'],\n",
    "                                         output_dim=kargs['embedding_dimension'])\n",
    "        self.lstm_1_layer = tf.keras.layers.LSTM(kargs['lstm_dimension'],\n",
    "                                                return_sequences=True)\n",
    "        self.lstm_2_layer = tf.keras.layers.LSTM(kargs['lstm_dimension'])\n",
    "        self.dropout = layers.Dropout(kargs['dropout_rate'])\n",
    "        self.fc1 = layers.Dense(units=kargs['dense_dimension'],\n",
    "                               activation=tf.keras.activations.tanh)\n",
    "        self.fc2= layers.Dense(units=kargs['output_dimension'],\n",
    "                              activation=tf.keras.activations.sigmoid)\n",
    "        \n",
    "        def call(self, x):\n",
    "            x = self.embedding(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.lstm_1_layer(x)\n",
    "            x = self.lstm_2_layer(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc1(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "             metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/0105l/Desktop/고려대학교/대학교_비교과/2021.1학기/KUS실전연구문제단/자연어처리책 실습/data_out/rnn_classifier_en -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
